# What is Machine Learning?
__Machine Learning__ has become a buzzword in the field of technology nowadays. There is race among enterprises to add functionalities in their operations by using machine learning. This has also increased the opportunities for aspiring data scientists. So having knowledge of machine learning is crucial at this moment for every tech enthusiast.
**Machine Learning in simple words is teaching computers to learn by themselves without explicitly programming them so that they can perform various repetitive tasks by themselves.** Since machines never get
tired like humans they can do tasks for longer time. Machines learn when we teach them the pattern of doing any work. They start learning by themselves when they start recoignizing the pattern.
For example, the task of filling water in the tank whenever the tank gets empty. If we teach the machine to detect whether the tank is empty or full and start the motor whenever the tank is empty, it would do this repetitive task on its own. Similarly we can also teach it to stop the motor whenever the tank is full by detecting the water level in the tank.
 ```So the aim of Machine Learning is enabling machines to learn by themselves. Machines need a machine learning model to learn. Data is collected and fed into the machine learning model so that machines can recognize the pattern and do the work on their own.```
## Steps for preparing a machine learning model are
1. ### Collection of Data
	```We need to collect the right data according to the problem we want to solve. Different problems have different types of data. We can search for the relevant datasets from sources like Google Datasets Search, UCI Machine Learning Repository and other external repositories.```
`
2. ### Handling the missing data
    ```After the collection of data, it is necessary to assess the condition of the data. Since the collected data is rarely perfect dataset, we need to look for incorrect, inconsistent or missing data.```
3. ### Making the data consistent
    ```The data should be formatted so that it fits our machine learning model. There is irregualrity in the data when it is collected from different sources. There can also be aberration in the datasets if it has been collected by more than one person. There is decrease in errors when the data is formatted consistently.```
4. ### Deciding important key factors
     ```It is the job of our model to decide which feature is important and which is not on the basis of its affect on the output. We can simply provide the data sets and let the machine do it's job.But doing this consumes more power and time. So we can help our model by not feeding the features that are unrelated to the output.```
5. ### Splitting data into training and testing sets
	```This is the final step in preparing our model that involves splitting our data into two sets. The first set of data to train our algorithm and another set for testing. The selected data for training and testing should not be overlapping subsets of our dataset.```
In this way we build our machine learning model by following the above mentioned steps. Once the model is built, we deploy the models.
# Why Machine Learning?
## Applications of Machine Learning
Machine Learning has numerous applications in our daily life. We see the use of machine learning everyday but are not aware of it. Some examples where machine learning is applied are:
```
1. Face detection and finger print detection in our smartphones for unlocking our devices
2. Recommendations in social media sites on the basis of our browsing history
3. Fraud transactions detection system used by banks
4. Netflix movies recommendation on the basis of our watch history
```
These are only some few examples of use of machine learning models that we encounter daily. There are many such examples where machine learning is applied.
## Important Machine Learning Algorithms
Good understanding of the following algorithms is required.
### Linear regression
We aim to predict a target variable using some given data variables. What we can do is to pass a line from the data set fitting the data set as shown.
To generalise, you draw a straight line such that it crosses through the maximum number of points. Once we have done that, we can predict the target value using that line as the hypothesis function.
<br/>![linear regression](https://www.researchgate.net/profile/Hieu_Tran33/publication/333457161/figure/fig3/AS:763959762247682@1559153609649/Linear-Regression-model-sample-illustration.ppm)<br/>
The only problem is how to define the values of slop and intercept of the line.
<br/>![linear regression intuition](https://miro.medium.com/max/656/1*4nBp-NeOFGBc-nNzP-VG3w.png)<br/>
We can use calculus to get the minimum values of slope and intercept such that the line passes through maximum number of points. More commonly, gradient descent is used for updating parameters at each step. [Gradient descent](https://machinelearningmastery.com/linear-regression-tutorial-using-gradient-descent-for-machine-learning/#:~:text=Gradient%20Descent%20is%20the%20process,downhill%20towards%20the%20minimum%20value.), [more details.](https://en.wikipedia.org/wiki/Linear_regression#:~:text=In%20statistics%2C%20linear%20regression%20is,is%20called%20simple%20linear%20regression.)
We will not go into detailed mathematics because this note just provides intuition for the algorithms.
### Polynomial Regression
Sometimes the line may not fit the data because of the data might have a high dimensional polynomial nature. So a line won't be enough. For this we need to increase the degee of attibutes (which can be done using the scikit-learn library).
Check the below figure for linear regression.
<br/>![linear regression](https://miro.medium.com/max/875/1*US9Nk7SxtBlwvAswpXehng.png)<br/>
As you can see in the figure, the given line can fit the data almost perfectly. Simple linear regression is fine in this case.
Now look at this figure.
<br/>![polynomial regression](https://miro.medium.com/max/875/1*MhTfu8jmERKpstkYCc7n3w.png)<br/>
The line for predicted speeds is not able to fit the ground truth perfectly. The data is too complex for simple linear regression to make predictions. We need to have high degree attributes.
Now look at this figure.
<br/>![polynomial regression](https://miro.medium.com/max/875/1*866wXGUKYkkwgguk3o-8Gg.png)<br/>
This hypothesis function fits the data almost perfectly. So to decide between linear and polynomial regression, you have to visualize the data. Use python's seaborn for better aid in visualization.
For detailed mathematics behind polynomial regression, [Click Here](https://en.wikipedia.org/wiki/Polynomial_regression)
### Random Forest Regression
First let's look at Ensemble Learning. Ensemble learning is a technique that combines the predictions from multiple weak machine learning algorithms together to make more accurate predictions. Since the model is comprised of many models, it is called an Ensemble model. Look at the image below for better understanding.
<br/>![ensemble](https://miro.medium.com/max/434/0*IsQCuCZCTX_zc7Xy.png)<br/>
Random forest is an supervised machine learning that can be used for classification and regression. It has trees which have no interaction in between them, they are completely independent from each other. Each tree acts as an independent model, which can be combined with others to form an ensemble. Each tree uses random data from the original data set when generating its splits, adding randomness to prevent overfitting. For many data sets, it produces a highly accurate classifier. It gives estimates of what variables that are important in the classification therefore, can be used for feature selection. It has an effective method for estimating missing data while maintaining accuracy.
<br/>![random forests](https://miro.medium.com/max/656/0*f_qQPFpdofWGLQqc.png)<br/>
### Support Vector Regression
SVM is one of the most powerful machine learning algorithm available today. A linear regression is only able to generate a line to predict the data points, while a support vector regression can also generate a hyperplane. In SVM, Margin is the perpendicular distance between the hyperplane and the closest points. SVM tries to maximise this margin, no penalty region in built by SVM in the muti dimensional data.
<br/>Look at the image.<br/>
![SVM](https://miro.medium.com/max/875/0*uwRVvFVLmKi3T9pS.png)<br/>
Making a hyperplane to fit this data is very difficult, specially it it's high dimensional. SVM does this task perfectly. SVR tries to have as many support vectors as possible within the margin, thus it keeps the error within the threshold.
A major difference between Linear regression and SVR lies on the fact that Linear regression tends to minimize the error and SVR tends to keep it within a threshold.
For further information visit [Sklearn SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)
## When to use what? ðŸ˜•ðŸ˜•
- Linear regression is a linear model, which means it works really great with data with linear properties. But, linear model cannot capture the non-linear features.
- So in this case, you can use the decision trees or random forests which do a better job at capturing the non-linearity in the data by dividing the space into smaller sub-spaces.
- Random forests behave like ensemble models, making decision trees even more robust to deal with noisy data, whereas standard regression methods can get easily confused by noise and will result in high error. 
- Normally, Support Vectors models perform better on sparse data than RF. Moreover, Decision trees work faster, non-linear data are handled well . Also they train faster but they have tendency to overfit.


Machine Learning has numerous applications in our daily life. We see the use of machine learning
everyday but are not aware of it. Some examples where machine learning is applied are:
```
1. Face detection and finger print detection in our smartphones for unlocking our devices
2. Recommendations in social media sites on the basis of our browsing history
3. Fraud transactions detection system used by banks
4. Netflix movies recommendation on the basis of our watch history
```
These are only some few examples of use of machine learning models that we encounter daily. There
are many such examples where machine learning is applied..
