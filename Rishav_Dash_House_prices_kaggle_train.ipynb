{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                     Kaggle House Price Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset from [here!!](https://www.kaggle.com/c/home-data-for-ml-course/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "                 ... \n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns having more missing value and fill the categorial features with its mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df.select_dtypes(include=['object']).copy()\n",
    "categorical_features = features.columns\n",
    "cat_columns = []\n",
    "for i in categorical_features:\n",
    "    cat_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df.isna().sum():\n",
    "#     if i> 0:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8b6007c10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])\n",
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding with multiple columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1    AllPub    Corner       Gtl  ...          36             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          34             0         0   \n",
       "3    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "4    AllPub    Inside       Gtl  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0         120        0        0       6    2010        WD        Normal  \n",
       "1           0        0    12500       6    2010        WD        Normal  \n",
       "2           0        0        0       3    2010        WD        Normal  \n",
       "3           0        0        0       6    2010        WD        Normal  \n",
       "4         144        0        0       1    2010        WD        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data appended to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/91992/Machine_learning/venv/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.concat([df, test_df], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition1\n",
      "Condition2\n",
      "BldgType\n",
      "HouseStyle\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "ExterQual\n",
      "ExterCond\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n",
      "SaleType\n",
      "SaleCondition\n"
     ]
    }
   ],
   "source": [
    "final_df = category_onehot_multcols(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing the duplicate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating training and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = final_df.iloc[:1422,:]\n",
    "df_test = final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/91992/Machine_learning/venv/lib/python2.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_test.drop(['SalePrice'], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.560e+02, 8.540e+02, 0.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.262e+03, 0.000e+00, 0.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [9.200e+02, 8.660e+02, 0.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.188e+03, 1.152e+03, 0.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.078e+03, 0.000e+00, 0.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.256e+03, 0.000e+00, 0.000e+00, ..., 0.000e+00, 1.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['SalePrice'], axis =1)\n",
    "y_train = df_train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(['SalePrice'], axis =1)\n",
    "y_test = df_test['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and model building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "classifier = xgboost.XGBRegressor()\n",
    "classifier.fit(X_train,  y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename= 'XGBmodel.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(y_pred)\n",
    "sub_df = pd.read_csv('sample_submission.csv')\n",
    "dataset = pd.concat([sub_df['Id'], pred], axis= 1)\n",
    "dataset.columns= ['Id', 'SalePrice']\n",
    "dataset.to_csv('my_submissionk.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv = RandomizedSearchCV(estimator=classifier,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=4,\n",
       "          param_distributions={'learning_rate': [0.05, 0.1, 0.15, 0.2], 'base_score': [0.25, 0.5, 0.75, 1], 'n_estimators': [100, 500, 900, 1100, 1500], 'min_child_weight': [1, 2, 3, 4], 'max_depth': [2, 3, 5, 10, 15], 'booster': ['gbtree', 'gblinear']},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "          verbose=5)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=1, missing=None, n_estimators=900, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USing XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "       min_child_weight=1, missing=None, n_estimators=900, n_jobs=1,\n",
    "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=1, missing=None, n_estimators=900, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your model as a pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename= 'XGBmodel.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(y_pred)\n",
    "sub_df = pd.read_csv('sample_submission.csv')\n",
    "dataset = pd.concat([sub_df['Id'], pred], axis= 1)\n",
    "dataset.columns= ['Id', 'SalePrice']\n",
    "dataset.to_csv('my_submission_new.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the Neural Network Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function for calculating RMSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return tf.sqrt(tf.reduce_mean((y_pred - y_true)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1137 samples, validate on 285 samples\n",
      "Epoch 1/500\n",
      "1137/1137 [==============================] - 1s 1ms/sample - loss: 186121.7801 - val_loss: 166847.5096\n",
      "Epoch 2/500\n",
      "1137/1137 [==============================] - 0s 386us/sample - loss: 112623.1769 - val_loss: 68930.0704\n",
      "Epoch 3/500\n",
      "1137/1137 [==============================] - 0s 395us/sample - loss: 69764.7946 - val_loss: 67111.8218\n",
      "Epoch 4/500\n",
      "1137/1137 [==============================] - 0s 389us/sample - loss: 68397.6867 - val_loss: 65781.0097\n",
      "Epoch 5/500\n",
      "1137/1137 [==============================] - 0s 404us/sample - loss: 66088.0575 - val_loss: 64639.5333\n",
      "Epoch 6/500\n",
      "1137/1137 [==============================] - 0s 376us/sample - loss: 64444.3178 - val_loss: 63611.8624\n",
      "Epoch 7/500\n",
      "1137/1137 [==============================] - 0s 316us/sample - loss: 62623.7104 - val_loss: 62536.5990\n",
      "Epoch 8/500\n",
      "1137/1137 [==============================] - 0s 407us/sample - loss: 61635.5878 - val_loss: 61673.1335\n",
      "Epoch 9/500\n",
      "1137/1137 [==============================] - 0s 330us/sample - loss: 60085.4361 - val_loss: 60671.9662\n",
      "Epoch 10/500\n",
      "1137/1137 [==============================] - 0s 363us/sample - loss: 57551.6947 - val_loss: 60158.3723\n",
      "Epoch 11/500\n",
      "1137/1137 [==============================] - 0s 374us/sample - loss: 57524.5321 - val_loss: 59076.1108\n",
      "Epoch 12/500\n",
      "1137/1137 [==============================] - 0s 355us/sample - loss: 55528.1974 - val_loss: 57890.0323\n",
      "Epoch 13/500\n",
      "1137/1137 [==============================] - 0s 368us/sample - loss: 54818.5250 - val_loss: 57122.8958\n",
      "Epoch 14/500\n",
      "1137/1137 [==============================] - 0s 438us/sample - loss: 54103.1763 - val_loss: 56480.4207\n",
      "Epoch 15/500\n",
      "1137/1137 [==============================] - 0s 381us/sample - loss: 52217.8767 - val_loss: 55317.7609\n",
      "Epoch 16/500\n",
      "1137/1137 [==============================] - 0s 365us/sample - loss: 50306.9037 - val_loss: 54422.4687\n",
      "Epoch 17/500\n",
      "1137/1137 [==============================] - 0s 368us/sample - loss: 49487.4941 - val_loss: 53549.7287\n",
      "Epoch 18/500\n",
      "1137/1137 [==============================] - 0s 382us/sample - loss: 48191.8624 - val_loss: 52577.8643\n",
      "Epoch 19/500\n",
      "1137/1137 [==============================] - 0s 357us/sample - loss: 46891.0924 - val_loss: 52363.2005\n",
      "Epoch 20/500\n",
      "1137/1137 [==============================] - 0s 364us/sample - loss: 45634.9837 - val_loss: 50906.9205\n",
      "Epoch 21/500\n",
      "1137/1137 [==============================] - 0s 373us/sample - loss: 44843.8870 - val_loss: 50005.7043\n",
      "Epoch 22/500\n",
      "1137/1137 [==============================] - 0s 384us/sample - loss: 43380.7583 - val_loss: 49358.1852\n",
      "Epoch 23/500\n",
      "1137/1137 [==============================] - 0s 368us/sample - loss: 41544.2006 - val_loss: 48346.6786\n",
      "Epoch 24/500\n",
      "1137/1137 [==============================] - 0s 412us/sample - loss: 40512.6101 - val_loss: 47453.2902\n",
      "Epoch 25/500\n",
      "1137/1137 [==============================] - 0s 309us/sample - loss: 39474.8867 - val_loss: 46980.3942\n",
      "Epoch 26/500\n",
      "1137/1137 [==============================] - 0s 385us/sample - loss: 38976.8503 - val_loss: 46477.1988\n",
      "Epoch 27/500\n",
      "1137/1137 [==============================] - 0s 395us/sample - loss: 38151.8394 - val_loss: 46428.1264\n",
      "Epoch 28/500\n",
      "1137/1137 [==============================] - 0s 354us/sample - loss: 37876.7577 - val_loss: 45909.9728\n",
      "Epoch 29/500\n",
      "1137/1137 [==============================] - 1s 510us/sample - loss: 37315.6240 - val_loss: 46256.3203\n",
      "Epoch 30/500\n",
      "1137/1137 [==============================] - 0s 366us/sample - loss: 37762.7329 - val_loss: 45953.4103\n",
      "Epoch 31/500\n",
      "1137/1137 [==============================] - 1s 524us/sample - loss: 37024.8324 - val_loss: 45387.1062\n",
      "Epoch 32/500\n",
      "1137/1137 [==============================] - 0s 392us/sample - loss: 36739.4187 - val_loss: 45642.1795\n",
      "Epoch 33/500\n",
      "1137/1137 [==============================] - 0s 411us/sample - loss: 36633.6511 - val_loss: 45338.4720\n",
      "Epoch 34/500\n",
      "1137/1137 [==============================] - 0s 308us/sample - loss: 36441.1029 - val_loss: 45295.0237\n",
      "Epoch 35/500\n",
      "1137/1137 [==============================] - 0s 401us/sample - loss: 36895.6904 - val_loss: 45597.6999\n",
      "Epoch 36/500\n",
      "1137/1137 [==============================] - 0s 376us/sample - loss: 36592.0452 - val_loss: 45181.3242\n",
      "Epoch 37/500\n",
      "1137/1137 [==============================] - 0s 397us/sample - loss: 36597.5355 - val_loss: 45142.3447\n",
      "Epoch 38/500\n",
      "1137/1137 [==============================] - 0s 362us/sample - loss: 35680.2154 - val_loss: 47931.1494\n",
      "Epoch 39/500\n",
      "1137/1137 [==============================] - 1s 526us/sample - loss: 36342.6399 - val_loss: 45105.2722\n",
      "Epoch 40/500\n",
      "1137/1137 [==============================] - 0s 339us/sample - loss: 36575.7953 - val_loss: 45132.6769\n",
      "Epoch 41/500\n",
      "1137/1137 [==============================] - 1s 480us/sample - loss: 36290.1531 - val_loss: 45224.5880\n",
      "Epoch 42/500\n",
      "1137/1137 [==============================] - 3s 2ms/sample - loss: 36524.8046 - val_loss: 45082.6986\n",
      "Epoch 43/500\n",
      "1137/1137 [==============================] - 1s 1ms/sample - loss: 35578.2710 - val_loss: 45125.8085\n",
      "Epoch 44/500\n",
      "1137/1137 [==============================] - 1s 648us/sample - loss: 36022.9383 - val_loss: 45084.3747\n",
      "Epoch 45/500\n",
      "1137/1137 [==============================] - 0s 434us/sample - loss: 36422.6936 - val_loss: 45865.1591\n",
      "Epoch 46/500\n",
      "1137/1137 [==============================] - 0s 341us/sample - loss: 36548.4573 - val_loss: 45624.1040\n",
      "Epoch 47/500\n",
      "1137/1137 [==============================] - 0s 423us/sample - loss: 35892.6902 - val_loss: 45411.5906\n",
      "Epoch 48/500\n",
      "1137/1137 [==============================] - 0s 383us/sample - loss: 36505.9117 - val_loss: 45073.7523\n",
      "Epoch 49/500\n",
      "1137/1137 [==============================] - 0s 366us/sample - loss: 36126.4732 - val_loss: 45254.6617\n",
      "Epoch 50/500\n",
      "1137/1137 [==============================] - 0s 383us/sample - loss: 35963.8226 - val_loss: 45218.5236\n",
      "Epoch 51/500\n",
      "1137/1137 [==============================] - 0s 416us/sample - loss: 36093.9021 - val_loss: 45613.3354\n",
      "Epoch 52/500\n",
      "1137/1137 [==============================] - 1s 445us/sample - loss: 36382.8886 - val_loss: 45042.7011\n",
      "Epoch 53/500\n",
      "1137/1137 [==============================] - 1s 505us/sample - loss: 35842.8767 - val_loss: 44879.5195\n",
      "Epoch 54/500\n",
      "1137/1137 [==============================] - 1s 1ms/sample - loss: 36197.3012 - val_loss: 44942.3365\n",
      "Epoch 55/500\n",
      "1137/1137 [==============================] - 1s 557us/sample - loss: 35846.4845 - val_loss: 45408.4206\n",
      "Epoch 56/500\n",
      "1137/1137 [==============================] - 1s 489us/sample - loss: 35853.0620 - val_loss: 45601.0346\n",
      "Epoch 57/500\n",
      "1137/1137 [==============================] - 0s 394us/sample - loss: 35428.3352 - val_loss: 45044.2049\n",
      "Epoch 58/500\n",
      "1137/1137 [==============================] - 0s 357us/sample - loss: 35922.7546 - val_loss: 45029.9280\n",
      "Epoch 59/500\n",
      "1137/1137 [==============================] - 0s 387us/sample - loss: 35636.2433 - val_loss: 45082.5855\n",
      "Epoch 60/500\n",
      "1137/1137 [==============================] - 0s 396us/sample - loss: 35924.5474 - val_loss: 45095.3538\n",
      "Epoch 61/500\n",
      "1137/1137 [==============================] - 0s 425us/sample - loss: 35955.6694 - val_loss: 45408.0384\n",
      "Epoch 62/500\n",
      "1137/1137 [==============================] - 0s 332us/sample - loss: 35076.4108 - val_loss: 45561.0336\n",
      "Epoch 63/500\n",
      "1137/1137 [==============================] - 0s 320us/sample - loss: 35953.4355 - val_loss: 44909.9488\n",
      "Epoch 64/500\n",
      "1137/1137 [==============================] - 0s 437us/sample - loss: 35869.8329 - val_loss: 45889.1790\n",
      "Epoch 65/500\n",
      "1137/1137 [==============================] - 0s 436us/sample - loss: 35587.6133 - val_loss: 45362.7213\n",
      "Epoch 66/500\n",
      "1137/1137 [==============================] - 0s 371us/sample - loss: 35987.3802 - val_loss: 45014.0253\n",
      "Epoch 67/500\n",
      "1137/1137 [==============================] - 0s 403us/sample - loss: 35435.0146 - val_loss: 44784.1309\n",
      "Epoch 68/500\n",
      "1137/1137 [==============================] - 0s 378us/sample - loss: 35737.3641 - val_loss: 45081.1088\n",
      "Epoch 69/500\n",
      "1137/1137 [==============================] - 0s 341us/sample - loss: 35602.3594 - val_loss: 44969.4545\n",
      "Epoch 70/500\n",
      "1137/1137 [==============================] - 0s 399us/sample - loss: 35228.0855 - val_loss: 45289.4269\n",
      "Epoch 71/500\n",
      "1137/1137 [==============================] - 0s 409us/sample - loss: 35795.8221 - val_loss: 44691.7080\n",
      "Epoch 72/500\n",
      "1137/1137 [==============================] - 0s 414us/sample - loss: 35874.3231 - val_loss: 44677.7966\n",
      "Epoch 73/500\n",
      "1137/1137 [==============================] - 0s 363us/sample - loss: 35741.8524 - val_loss: 45444.8457\n",
      "Epoch 74/500\n",
      "1137/1137 [==============================] - 0s 401us/sample - loss: 35495.2426 - val_loss: 44678.2903\n",
      "Epoch 75/500\n",
      "1137/1137 [==============================] - 1s 461us/sample - loss: 35986.5095 - val_loss: 44642.5916\n",
      "Epoch 76/500\n",
      "1137/1137 [==============================] - 0s 407us/sample - loss: 34815.2455 - val_loss: 46133.3880\n",
      "Epoch 77/500\n",
      "1137/1137 [==============================] - 0s 334us/sample - loss: 35726.2670 - val_loss: 44812.6712\n",
      "Epoch 78/500\n",
      "1137/1137 [==============================] - 0s 286us/sample - loss: 35608.5095 - val_loss: 44626.5677\n",
      "Epoch 79/500\n",
      "1137/1137 [==============================] - 0s 349us/sample - loss: 35578.6323 - val_loss: 44854.3381\n",
      "Epoch 80/500\n",
      "1137/1137 [==============================] - 0s 422us/sample - loss: 35341.7321 - val_loss: 44931.0397\n",
      "Epoch 81/500\n",
      "1137/1137 [==============================] - 0s 359us/sample - loss: 35441.4860 - val_loss: 44522.1663\n",
      "Epoch 82/500\n",
      "1137/1137 [==============================] - 0s 396us/sample - loss: 35087.8302 - val_loss: 44543.3092\n",
      "Epoch 83/500\n",
      "1137/1137 [==============================] - 0s 380us/sample - loss: 35473.2916 - val_loss: 44628.0692\n",
      "Epoch 84/500\n",
      "1137/1137 [==============================] - 0s 433us/sample - loss: 35743.1651 - val_loss: 45239.7752\n",
      "Epoch 85/500\n",
      "1137/1137 [==============================] - 1s 573us/sample - loss: 35542.9669 - val_loss: 44473.2085\n",
      "Epoch 86/500\n",
      "1137/1137 [==============================] - 0s 380us/sample - loss: 35627.7475 - val_loss: 44977.4299\n",
      "Epoch 87/500\n",
      "1137/1137 [==============================] - 1s 504us/sample - loss: 35296.0629 - val_loss: 44540.9364\n",
      "Epoch 88/500\n",
      "1137/1137 [==============================] - 1s 1ms/sample - loss: 35535.7489 - val_loss: 44563.8736\n",
      "Epoch 89/500\n",
      "1137/1137 [==============================] - 1s 933us/sample - loss: 35391.4550 - val_loss: 44551.0083\n",
      "Epoch 90/500\n",
      "1137/1137 [==============================] - 0s 428us/sample - loss: 35372.0416 - val_loss: 44475.0812\n",
      "Epoch 91/500\n",
      "1137/1137 [==============================] - 1s 510us/sample - loss: 35589.1644 - val_loss: 44503.9415\n",
      "Epoch 92/500\n",
      "1137/1137 [==============================] - 1s 616us/sample - loss: 35103.2433 - val_loss: 45403.7095\n",
      "Epoch 93/500\n",
      "1137/1137 [==============================] - 1s 609us/sample - loss: 35479.6907 - val_loss: 44723.4847\n",
      "Epoch 94/500\n",
      "1137/1137 [==============================] - 0s 348us/sample - loss: 35737.2181 - val_loss: 45020.4154\n",
      "Epoch 95/500\n",
      "1137/1137 [==============================] - 0s 345us/sample - loss: 35819.3787 - val_loss: 44505.7867\n",
      "Epoch 96/500\n",
      "1137/1137 [==============================] - 1s 649us/sample - loss: 35043.4503 - val_loss: 44391.7857\n",
      "Epoch 97/500\n",
      "1137/1137 [==============================] - 0s 399us/sample - loss: 35881.3084 - val_loss: 44416.2894\n",
      "Epoch 98/500\n",
      "1137/1137 [==============================] - 0s 339us/sample - loss: 35163.7958 - val_loss: 44283.5317\n",
      "Epoch 99/500\n",
      "1137/1137 [==============================] - 1s 716us/sample - loss: 35121.5839 - val_loss: 44387.4703\n",
      "Epoch 100/500\n",
      "1137/1137 [==============================] - 1s 472us/sample - loss: 34997.6806 - val_loss: 44510.4784\n",
      "Epoch 101/500\n",
      "1137/1137 [==============================] - 1s 462us/sample - loss: 35402.9796 - val_loss: 44382.5409\n",
      "Epoch 102/500\n",
      "1137/1137 [==============================] - 0s 410us/sample - loss: 35665.9634 - val_loss: 44810.8231\n",
      "Epoch 103/500\n",
      "1137/1137 [==============================] - 1s 456us/sample - loss: 35407.9707 - val_loss: 45089.9703\n",
      "Epoch 104/500\n",
      "1137/1137 [==============================] - 1s 524us/sample - loss: 34970.5904 - val_loss: 44248.1396\n",
      "Epoch 105/500\n",
      "1137/1137 [==============================] - 1s 516us/sample - loss: 35071.3839 - val_loss: 44574.6690\n",
      "Epoch 106/500\n",
      "1137/1137 [==============================] - 0s 420us/sample - loss: 35105.5916 - val_loss: 44287.6731\n",
      "Epoch 107/500\n",
      "1137/1137 [==============================] - 1s 477us/sample - loss: 35153.7716 - val_loss: 44272.9652\n",
      "Epoch 108/500\n",
      "1137/1137 [==============================] - 1s 508us/sample - loss: 34759.5519 - val_loss: 44586.6285\n",
      "Epoch 109/500\n",
      "1137/1137 [==============================] - 1s 546us/sample - loss: 35125.6012 - val_loss: 44907.7873\n",
      "Epoch 110/500\n",
      "1137/1137 [==============================] - 1s 515us/sample - loss: 35119.9548 - val_loss: 44356.6518\n",
      "Epoch 111/500\n",
      "1137/1137 [==============================] - 1s 552us/sample - loss: 35432.7514 - val_loss: 44405.8423\n",
      "Epoch 112/500\n",
      "1137/1137 [==============================] - 1s 487us/sample - loss: 34931.9216 - val_loss: 44247.1988\n",
      "Epoch 113/500\n",
      "1137/1137 [==============================] - 1s 479us/sample - loss: 34984.5940 - val_loss: 44249.3188\n",
      "Epoch 114/500\n",
      "1137/1137 [==============================] - 1s 514us/sample - loss: 34432.8619 - val_loss: 44365.1501\n",
      "Epoch 115/500\n",
      "1137/1137 [==============================] - 1s 482us/sample - loss: 34919.4827 - val_loss: 44083.7991\n",
      "Epoch 116/500\n",
      "1137/1137 [==============================] - 0s 422us/sample - loss: 34344.4432 - val_loss: 44404.8567\n",
      "Epoch 117/500\n",
      "1137/1137 [==============================] - 1s 468us/sample - loss: 34815.6602 - val_loss: 44229.9708\n",
      "Epoch 118/500\n",
      "1137/1137 [==============================] - 1s 581us/sample - loss: 34620.1595 - val_loss: 44167.4336\n",
      "Epoch 119/500\n",
      "1137/1137 [==============================] - 1s 460us/sample - loss: 34829.2104 - val_loss: 44323.0680\n",
      "Epoch 120/500\n",
      "1137/1137 [==============================] - 1s 487us/sample - loss: 35190.5712 - val_loss: 44782.1315\n",
      "Epoch 121/500\n",
      "1137/1137 [==============================] - 1s 520us/sample - loss: 34483.2350 - val_loss: 44051.1973\n",
      "Epoch 122/500\n",
      "1137/1137 [==============================] - 1s 477us/sample - loss: 34587.2325 - val_loss: 44500.3403\n",
      "Epoch 123/500\n",
      "1137/1137 [==============================] - 1s 621us/sample - loss: 34565.6615 - val_loss: 45551.2211\n",
      "Epoch 124/500\n",
      "1137/1137 [==============================] - 0s 428us/sample - loss: 34619.6409 - val_loss: 44091.2563\n",
      "Epoch 125/500\n",
      "1137/1137 [==============================] - 1s 455us/sample - loss: 34455.3995 - val_loss: 44536.9526\n",
      "Epoch 126/500\n",
      "1137/1137 [==============================] - 1s 672us/sample - loss: 34741.6562 - val_loss: 44143.2244\n",
      "Epoch 127/500\n",
      "1137/1137 [==============================] - 1s 773us/sample - loss: 34367.1264 - val_loss: 43937.2678\n",
      "Epoch 128/500\n",
      "1137/1137 [==============================] - 1s 512us/sample - loss: 35161.1297 - val_loss: 43937.5655\n",
      "Epoch 129/500\n",
      "1137/1137 [==============================] - 0s 406us/sample - loss: 34273.4125 - val_loss: 44968.1102\n",
      "Epoch 130/500\n",
      "1137/1137 [==============================] - 1s 498us/sample - loss: 34552.2938 - val_loss: 43991.7883\n",
      "Epoch 131/500\n",
      "1137/1137 [==============================] - 1s 448us/sample - loss: 34636.6039 - val_loss: 44134.6094\n",
      "Epoch 132/500\n",
      "1137/1137 [==============================] - 1s 517us/sample - loss: 33980.6176 - val_loss: 43903.7740\n",
      "Epoch 133/500\n",
      "1137/1137 [==============================] - 1s 468us/sample - loss: 34296.4835 - val_loss: 45104.6273\n",
      "Epoch 134/500\n",
      "1137/1137 [==============================] - 1s 454us/sample - loss: 34175.4783 - val_loss: 44636.1652\n",
      "Epoch 135/500\n",
      "1137/1137 [==============================] - 1s 454us/sample - loss: 34215.7649 - val_loss: 43798.3934\n",
      "Epoch 136/500\n",
      "1137/1137 [==============================] - 1s 497us/sample - loss: 34169.5113 - val_loss: 43742.7896\n",
      "Epoch 137/500\n",
      "1137/1137 [==============================] - 0s 435us/sample - loss: 34264.9831 - val_loss: 43669.0969\n",
      "Epoch 138/500\n",
      "1137/1137 [==============================] - 1s 509us/sample - loss: 34300.1830 - val_loss: 43689.2247\n",
      "Epoch 139/500\n",
      "1137/1137 [==============================] - 1s 443us/sample - loss: 33707.2187 - val_loss: 43684.2297\n",
      "Epoch 140/500\n",
      "1137/1137 [==============================] - 1s 487us/sample - loss: 34438.1525 - val_loss: 43888.9792\n",
      "Epoch 141/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 529us/sample - loss: 34137.6973 - val_loss: 44028.1500\n",
      "Epoch 142/500\n",
      "1137/1137 [==============================] - 0s 436us/sample - loss: 33762.8682 - val_loss: 43787.0192\n",
      "Epoch 143/500\n",
      "1137/1137 [==============================] - 1s 584us/sample - loss: 33988.7211 - val_loss: 43664.8031\n",
      "Epoch 144/500\n",
      "1137/1137 [==============================] - 1s 476us/sample - loss: 33749.3037 - val_loss: 43655.5211\n",
      "Epoch 145/500\n",
      "1137/1137 [==============================] - 1s 561us/sample - loss: 34264.3370 - val_loss: 43982.6007\n",
      "Epoch 146/500\n",
      "1137/1137 [==============================] - 1s 571us/sample - loss: 33966.7008 - val_loss: 43630.0892\n",
      "Epoch 147/500\n",
      "1137/1137 [==============================] - 1s 590us/sample - loss: 34094.7834 - val_loss: 44043.7344\n",
      "Epoch 148/500\n",
      "1137/1137 [==============================] - 1s 611us/sample - loss: 34389.9054 - val_loss: 43614.2060\n",
      "Epoch 149/500\n",
      "1137/1137 [==============================] - 1s 517us/sample - loss: 34106.7501 - val_loss: 44080.2972\n",
      "Epoch 150/500\n",
      "1137/1137 [==============================] - 1s 567us/sample - loss: 33590.3474 - val_loss: 43919.5382\n",
      "Epoch 151/500\n",
      "1137/1137 [==============================] - 0s 416us/sample - loss: 33717.6558 - val_loss: 43583.6604\n",
      "Epoch 152/500\n",
      "1137/1137 [==============================] - 1s 488us/sample - loss: 33526.8257 - val_loss: 44815.9137\n",
      "Epoch 153/500\n",
      "1137/1137 [==============================] - 1s 559us/sample - loss: 33545.7094 - val_loss: 44209.3515\n",
      "Epoch 154/500\n",
      "1137/1137 [==============================] - 0s 410us/sample - loss: 33385.1266 - val_loss: 44210.2425\n",
      "Epoch 155/500\n",
      "1137/1137 [==============================] - 1s 548us/sample - loss: 34086.0517 - val_loss: 43845.5983\n",
      "Epoch 156/500\n",
      "1137/1137 [==============================] - 0s 437us/sample - loss: 33591.4000 - val_loss: 43474.4458\n",
      "Epoch 157/500\n",
      "1137/1137 [==============================] - 1s 498us/sample - loss: 33067.2682 - val_loss: 43584.2600\n",
      "Epoch 158/500\n",
      "1137/1137 [==============================] - 1s 514us/sample - loss: 33205.6122 - val_loss: 43518.2483\n",
      "Epoch 159/500\n",
      "1137/1137 [==============================] - 1s 450us/sample - loss: 33806.9556 - val_loss: 45437.9215\n",
      "Epoch 160/500\n",
      "1137/1137 [==============================] - 1s 600us/sample - loss: 33230.8184 - val_loss: 43619.4437\n",
      "Epoch 161/500\n",
      "1137/1137 [==============================] - 1s 558us/sample - loss: 33723.9957 - val_loss: 43647.6261\n",
      "Epoch 162/500\n",
      "1137/1137 [==============================] - 1s 531us/sample - loss: 33516.8737 - val_loss: 43438.7050\n",
      "Epoch 163/500\n",
      "1137/1137 [==============================] - 1s 527us/sample - loss: 33603.6420 - val_loss: 43497.9825\n",
      "Epoch 164/500\n",
      "1137/1137 [==============================] - 1s 473us/sample - loss: 33312.8745 - val_loss: 43483.6539\n",
      "Epoch 165/500\n",
      "1137/1137 [==============================] - 1s 484us/sample - loss: 33096.8044 - val_loss: 43459.5821\n",
      "Epoch 166/500\n",
      "1137/1137 [==============================] - 0s 424us/sample - loss: 33261.8941 - val_loss: 44468.0645\n",
      "Epoch 167/500\n",
      "1137/1137 [==============================] - 1s 754us/sample - loss: 33404.8745 - val_loss: 44548.6308\n",
      "Epoch 168/500\n",
      "1137/1137 [==============================] - 1s 567us/sample - loss: 33298.2757 - val_loss: 44041.4675\n",
      "Epoch 169/500\n",
      "1137/1137 [==============================] - 1s 487us/sample - loss: 33329.0372 - val_loss: 43370.0760\n",
      "Epoch 170/500\n",
      "1137/1137 [==============================] - 1s 475us/sample - loss: 33200.5287 - val_loss: 43865.2424\n",
      "Epoch 171/500\n",
      "1137/1137 [==============================] - 1s 515us/sample - loss: 33295.8337 - val_loss: 43614.1846\n",
      "Epoch 172/500\n",
      "1137/1137 [==============================] - 1s 483us/sample - loss: 33286.2125 - val_loss: 43986.2033\n",
      "Epoch 173/500\n",
      "1137/1137 [==============================] - 1s 475us/sample - loss: 33094.6949 - val_loss: 43333.4487\n",
      "Epoch 174/500\n",
      "1137/1137 [==============================] - 1s 461us/sample - loss: 33302.2859 - val_loss: 43826.2463\n",
      "Epoch 175/500\n",
      "1137/1137 [==============================] - 1s 478us/sample - loss: 32546.2077 - val_loss: 43358.6216\n",
      "Epoch 176/500\n",
      "1137/1137 [==============================] - 1s 452us/sample - loss: 32934.3472 - val_loss: 43413.5466\n",
      "Epoch 177/500\n",
      "1137/1137 [==============================] - 1s 470us/sample - loss: 33039.3226 - val_loss: 43400.1945\n",
      "Epoch 178/500\n",
      "1137/1137 [==============================] - 1s 547us/sample - loss: 33111.2014 - val_loss: 43380.7330\n",
      "Epoch 179/500\n",
      "1137/1137 [==============================] - 1s 578us/sample - loss: 33044.9489 - val_loss: 43442.0945\n",
      "Epoch 180/500\n",
      "1137/1137 [==============================] - 1s 610us/sample - loss: 32155.3805 - val_loss: 46949.8812\n",
      "Epoch 181/500\n",
      "1137/1137 [==============================] - 1s 555us/sample - loss: 33386.3649 - val_loss: 43440.3753\n",
      "Epoch 182/500\n",
      "1137/1137 [==============================] - 1s 573us/sample - loss: 33020.4614 - val_loss: 44079.0768\n",
      "Epoch 183/500\n",
      "1137/1137 [==============================] - 1s 713us/sample - loss: 32658.1471 - val_loss: 43509.3837\n",
      "Epoch 184/500\n",
      "1137/1137 [==============================] - 1s 561us/sample - loss: 32462.0208 - val_loss: 43513.2428\n",
      "Epoch 185/500\n",
      "1137/1137 [==============================] - 1s 519us/sample - loss: 32610.1654 - val_loss: 43618.1049\n",
      "Epoch 186/500\n",
      "1137/1137 [==============================] - 0s 417us/sample - loss: 32696.4731 - val_loss: 43457.8860\n",
      "Epoch 187/500\n",
      "1137/1137 [==============================] - 1s 547us/sample - loss: 32895.3911 - val_loss: 43181.2419\n",
      "Epoch 188/500\n",
      "1137/1137 [==============================] - 1s 461us/sample - loss: 32579.1515 - val_loss: 43687.2185\n",
      "Epoch 189/500\n",
      "1137/1137 [==============================] - 0s 430us/sample - loss: 32619.1693 - val_loss: 43786.7719\n",
      "Epoch 190/500\n",
      "1137/1137 [==============================] - 1s 472us/sample - loss: 32441.2735 - val_loss: 44476.0694\n",
      "Epoch 191/500\n",
      "1137/1137 [==============================] - 0s 425us/sample - loss: 32978.1329 - val_loss: 43216.9235\n",
      "Epoch 192/500\n",
      "1137/1137 [==============================] - 1s 509us/sample - loss: 32157.9692 - val_loss: 43372.5972\n",
      "Epoch 193/500\n",
      "1137/1137 [==============================] - 1s 471us/sample - loss: 32575.3522 - val_loss: 43332.2500\n",
      "Epoch 194/500\n",
      "1137/1137 [==============================] - 0s 428us/sample - loss: 32102.3144 - val_loss: 43315.4961\n",
      "Epoch 195/500\n",
      "1137/1137 [==============================] - 1s 463us/sample - loss: 32392.0292 - val_loss: 43514.2552\n",
      "Epoch 196/500\n",
      "1137/1137 [==============================] - 1s 444us/sample - loss: 32050.9786 - val_loss: 43257.7963\n",
      "Epoch 197/500\n",
      "1137/1137 [==============================] - 1s 591us/sample - loss: 31673.8431 - val_loss: 43290.1798\n",
      "Epoch 198/500\n",
      "1137/1137 [==============================] - 1s 459us/sample - loss: 31976.9170 - val_loss: 43494.9699\n",
      "Epoch 199/500\n",
      "1137/1137 [==============================] - 1s 447us/sample - loss: 32254.0537 - val_loss: 43320.4872\n",
      "Epoch 200/500\n",
      "1137/1137 [==============================] - 1s 440us/sample - loss: 32102.1087 - val_loss: 43305.6942\n",
      "Epoch 201/500\n",
      "1137/1137 [==============================] - 0s 409us/sample - loss: 32617.0225 - val_loss: 43864.9710\n",
      "Epoch 202/500\n",
      "1137/1137 [==============================] - 1s 688us/sample - loss: 32160.8580 - val_loss: 43241.5172\n",
      "Epoch 203/500\n",
      "1137/1137 [==============================] - 1s 482us/sample - loss: 32029.2284 - val_loss: 43200.6219\n",
      "Epoch 204/500\n",
      "1137/1137 [==============================] - 1s 449us/sample - loss: 32097.2459 - val_loss: 43458.5441\n",
      "Epoch 205/500\n",
      "1137/1137 [==============================] - 1s 496us/sample - loss: 32158.2010 - val_loss: 43210.2677\n",
      "Epoch 206/500\n",
      "1137/1137 [==============================] - 0s 371us/sample - loss: 32442.2180 - val_loss: 44488.1137\n",
      "Epoch 207/500\n",
      "1137/1137 [==============================] - 0s 405us/sample - loss: 32190.0014 - val_loss: 43985.2913\n",
      "Epoch 208/500\n",
      "1137/1137 [==============================] - 1s 456us/sample - loss: 31592.8874 - val_loss: 43669.6718\n",
      "Epoch 209/500\n",
      "1137/1137 [==============================] - 1s 466us/sample - loss: 32087.2297 - val_loss: 44182.3965\n",
      "Epoch 210/500\n",
      "1137/1137 [==============================] - 0s 429us/sample - loss: 32206.3877 - val_loss: 44016.5868\n",
      "Epoch 211/500\n",
      "1137/1137 [==============================] - 1s 441us/sample - loss: 31797.9719 - val_loss: 43475.4693\n",
      "Epoch 212/500\n",
      "1137/1137 [==============================] - 0s 359us/sample - loss: 31931.3247 - val_loss: 44275.8054\n",
      "Epoch 213/500\n",
      "1137/1137 [==============================] - 1s 523us/sample - loss: 31801.1165 - val_loss: 44048.6717\n",
      "Epoch 214/500\n",
      "1137/1137 [==============================] - 0s 404us/sample - loss: 31740.0342 - val_loss: 43371.1187\n",
      "Epoch 215/500\n",
      "1137/1137 [==============================] - 1s 454us/sample - loss: 31742.3287 - val_loss: 43865.5709\n",
      "Epoch 216/500\n",
      "1137/1137 [==============================] - 0s 347us/sample - loss: 31800.0804 - val_loss: 43311.0437\n",
      "Epoch 217/500\n",
      "1137/1137 [==============================] - 0s 371us/sample - loss: 32044.0264 - val_loss: 43822.2973\n",
      "Epoch 218/500\n",
      "1137/1137 [==============================] - 0s 382us/sample - loss: 31758.9541 - val_loss: 43634.3224\n",
      "Epoch 219/500\n",
      "1137/1137 [==============================] - 1s 512us/sample - loss: 31680.1595 - val_loss: 43496.2700\n",
      "Epoch 220/500\n",
      "1137/1137 [==============================] - 0s 385us/sample - loss: 31228.8793 - val_loss: 43498.6312\n",
      "Epoch 221/500\n",
      "1137/1137 [==============================] - 1s 442us/sample - loss: 31502.8617 - val_loss: 43420.5568\n",
      "Epoch 222/500\n",
      "1137/1137 [==============================] - 0s 353us/sample - loss: 31511.7863 - val_loss: 43261.9444\n",
      "Epoch 223/500\n",
      "1137/1137 [==============================] - 0s 356us/sample - loss: 31832.1522 - val_loss: 43652.2224\n",
      "Epoch 224/500\n",
      "1137/1137 [==============================] - 0s 373us/sample - loss: 31443.7893 - val_loss: 43265.4121\n",
      "Epoch 225/500\n",
      "1137/1137 [==============================] - 0s 387us/sample - loss: 31302.2514 - val_loss: 43324.1663\n",
      "Epoch 226/500\n",
      "1137/1137 [==============================] - 0s 399us/sample - loss: 31264.7499 - val_loss: 44053.5575\n",
      "Epoch 227/500\n",
      "1137/1137 [==============================] - 0s 413us/sample - loss: 31479.1808 - val_loss: 43308.4813\n",
      "Epoch 228/500\n",
      "1137/1137 [==============================] - 0s 379us/sample - loss: 31533.9196 - val_loss: 44175.8101\n",
      "Epoch 229/500\n",
      "1137/1137 [==============================] - 0s 394us/sample - loss: 31696.3365 - val_loss: 43949.6311\n",
      "Epoch 230/500\n",
      "1137/1137 [==============================] - 1s 519us/sample - loss: 31072.3505 - val_loss: 43448.2865\n",
      "Epoch 231/500\n",
      "1137/1137 [==============================] - 0s 406us/sample - loss: 31059.5104 - val_loss: 43775.7525\n",
      "Epoch 232/500\n",
      "1137/1137 [==============================] - 0s 435us/sample - loss: 31376.9118 - val_loss: 43433.5189\n",
      "Epoch 233/500\n",
      "1137/1137 [==============================] - 0s 411us/sample - loss: 31225.8407 - val_loss: 43377.2566\n",
      "Epoch 234/500\n",
      "1137/1137 [==============================] - 0s 425us/sample - loss: 31026.4590 - val_loss: 43334.4623\n",
      "Epoch 235/500\n",
      "1137/1137 [==============================] - 0s 407us/sample - loss: 31230.5542 - val_loss: 43805.2407\n",
      "Epoch 236/500\n",
      "1137/1137 [==============================] - 1s 448us/sample - loss: 31463.7955 - val_loss: 43585.3385\n",
      "Epoch 237/500\n",
      "1137/1137 [==============================] - 0s 412us/sample - loss: 30490.8770 - val_loss: 43373.5150\n",
      "Epoch 238/500\n",
      "1137/1137 [==============================] - 0s 413us/sample - loss: 30769.0708 - val_loss: 43631.0530\n",
      "Epoch 239/500\n",
      "1137/1137 [==============================] - 0s 389us/sample - loss: 31177.1170 - val_loss: 43388.6558\n",
      "Epoch 240/500\n",
      "1137/1137 [==============================] - 0s 353us/sample - loss: 31379.8517 - val_loss: 43428.7411\n",
      "Epoch 241/500\n",
      "1137/1137 [==============================] - 1s 453us/sample - loss: 31075.2831 - val_loss: 43375.3273\n",
      "Epoch 242/500\n",
      "1137/1137 [==============================] - 1s 635us/sample - loss: 31346.8776 - val_loss: 43375.2230\n",
      "Epoch 243/500\n",
      "1137/1137 [==============================] - 1s 500us/sample - loss: 30665.4431 - val_loss: 45291.4606\n",
      "Epoch 244/500\n",
      "1137/1137 [==============================] - 0s 402us/sample - loss: 31486.5413 - val_loss: 43555.4681\n",
      "Epoch 245/500\n",
      "1137/1137 [==============================] - 0s 380us/sample - loss: 30921.3472 - val_loss: 43714.7308\n",
      "Epoch 246/500\n",
      "1137/1137 [==============================] - 0s 391us/sample - loss: 30744.8371 - val_loss: 44394.8128\n",
      "Epoch 247/500\n",
      "1137/1137 [==============================] - 0s 396us/sample - loss: 31010.9432 - val_loss: 43450.7342\n",
      "Epoch 248/500\n",
      "1137/1137 [==============================] - 1s 469us/sample - loss: 31030.2093 - val_loss: 43353.5322\n",
      "Epoch 249/500\n",
      "1137/1137 [==============================] - 0s 405us/sample - loss: 31033.6726 - val_loss: 43403.1434\n",
      "Epoch 250/500\n",
      "1137/1137 [==============================] - 0s 364us/sample - loss: 31219.7797 - val_loss: 44099.9445\n",
      "Epoch 251/500\n",
      "1137/1137 [==============================] - 0s 382us/sample - loss: 31012.1396 - val_loss: 44775.9120\n",
      "Epoch 252/500\n",
      "1137/1137 [==============================] - 0s 370us/sample - loss: 30761.0315 - val_loss: 43324.0917\n",
      "Epoch 253/500\n",
      "1137/1137 [==============================] - 0s 425us/sample - loss: 30702.3814 - val_loss: 43589.3968\n",
      "Epoch 254/500\n",
      "1137/1137 [==============================] - 1s 479us/sample - loss: 30952.3436 - val_loss: 43326.5617\n",
      "Epoch 255/500\n",
      "1137/1137 [==============================] - 0s 411us/sample - loss: 30760.1654 - val_loss: 43420.6175\n",
      "Epoch 256/500\n",
      "1137/1137 [==============================] - 0s 436us/sample - loss: 30644.2045 - val_loss: 43635.2593\n",
      "Epoch 257/500\n",
      "1137/1137 [==============================] - 1s 472us/sample - loss: 30909.7324 - val_loss: 43600.3190\n",
      "Epoch 258/500\n",
      "1137/1137 [==============================] - 0s 418us/sample - loss: 30654.2408 - val_loss: 43688.5270\n",
      "Epoch 259/500\n",
      "1137/1137 [==============================] - 0s 408us/sample - loss: 30874.5796 - val_loss: 43686.9276\n",
      "Epoch 260/500\n",
      "1137/1137 [==============================] - 0s 402us/sample - loss: 31072.8383 - val_loss: 44412.2975\n",
      "Epoch 261/500\n",
      "1137/1137 [==============================] - 0s 436us/sample - loss: 30531.6377 - val_loss: 43510.9622\n",
      "Epoch 262/500\n",
      "1137/1137 [==============================] - 0s 402us/sample - loss: 30848.8663 - val_loss: 43606.0535\n",
      "Epoch 263/500\n",
      "1137/1137 [==============================] - 0s 406us/sample - loss: 30694.2042 - val_loss: 43569.9011\n",
      "Epoch 264/500\n",
      "1137/1137 [==============================] - 1s 450us/sample - loss: 30444.4160 - val_loss: 44037.0654\n",
      "Epoch 265/500\n",
      "1137/1137 [==============================] - 0s 425us/sample - loss: 30601.7758 - val_loss: 43448.6486\n",
      "Epoch 266/500\n",
      "1137/1137 [==============================] - 1s 651us/sample - loss: 30532.4902 - val_loss: 44047.5257\n",
      "Epoch 267/500\n",
      "1137/1137 [==============================] - 1s 455us/sample - loss: 30674.0265 - val_loss: 43707.9230\n",
      "Epoch 268/500\n",
      "1137/1137 [==============================] - 1s 468us/sample - loss: 30194.3532 - val_loss: 44116.2263\n",
      "Epoch 269/500\n",
      "1137/1137 [==============================] - 1s 459us/sample - loss: 30948.1816 - val_loss: 43503.7831\n",
      "Epoch 270/500\n",
      "1137/1137 [==============================] - 1s 468us/sample - loss: 30431.6831 - val_loss: 43572.4394\n",
      "Epoch 271/500\n",
      "1137/1137 [==============================] - 0s 434us/sample - loss: 30513.1915 - val_loss: 44511.3279\n",
      "Epoch 272/500\n",
      "1137/1137 [==============================] - 1s 453us/sample - loss: 30993.7780 - val_loss: 43401.3501\n",
      "Epoch 273/500\n",
      "1137/1137 [==============================] - 0s 411us/sample - loss: 30856.6623 - val_loss: 43414.1564\n",
      "Epoch 274/500\n",
      "1137/1137 [==============================] - 1s 588us/sample - loss: 30447.2564 - val_loss: 43844.6837\n",
      "Epoch 275/500\n",
      "1137/1137 [==============================] - 0s 399us/sample - loss: 30364.2821 - val_loss: 46033.9699\n",
      "Epoch 276/500\n",
      "1137/1137 [==============================] - 1s 483us/sample - loss: 31013.7556 - val_loss: 43657.3925\n",
      "Epoch 277/500\n",
      "1137/1137 [==============================] - 0s 368us/sample - loss: 30529.4966 - val_loss: 43889.2617\n",
      "Epoch 278/500\n",
      "1137/1137 [==============================] - 0s 437us/sample - loss: 30025.0976 - val_loss: 43427.8743\n",
      "Epoch 279/500\n",
      "1137/1137 [==============================] - 0s 387us/sample - loss: 30810.8541 - val_loss: 43459.3755\n",
      "Epoch 280/500\n",
      "1137/1137 [==============================] - 1s 623us/sample - loss: 30585.0922 - val_loss: 43339.7329\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 0s 414us/sample - loss: 30204.9207 - val_loss: 43647.4452\n",
      "Epoch 282/500\n",
      "1137/1137 [==============================] - 1s 482us/sample - loss: 30058.1378 - val_loss: 43356.6545\n",
      "Epoch 283/500\n",
      "1137/1137 [==============================] - 0s 385us/sample - loss: 30167.7883 - val_loss: 43849.0530\n",
      "Epoch 284/500\n",
      "1137/1137 [==============================] - 1s 442us/sample - loss: 30781.4689 - val_loss: 44176.0856\n",
      "Epoch 285/500\n",
      "1137/1137 [==============================] - 1s 500us/sample - loss: 30417.6372 - val_loss: 43552.2805\n",
      "Epoch 286/500\n",
      "1137/1137 [==============================] - 1s 522us/sample - loss: 30415.0634 - val_loss: 44867.4792\n",
      "Epoch 287/500\n",
      "1137/1137 [==============================] - 0s 392us/sample - loss: 30111.4738 - val_loss: 43267.1371\n",
      "Epoch 288/500\n",
      "1137/1137 [==============================] - 0s 395us/sample - loss: 29988.6766 - val_loss: 43344.2364\n",
      "Epoch 289/500\n",
      "1137/1137 [==============================] - 1s 466us/sample - loss: 30351.2619 - val_loss: 43484.7969\n",
      "Epoch 290/500\n",
      "1137/1137 [==============================] - 0s 419us/sample - loss: 30246.5442 - val_loss: 43462.4133\n",
      "Epoch 291/500\n",
      "1137/1137 [==============================] - 0s 385us/sample - loss: 29577.1836 - val_loss: 44058.7741\n",
      "Epoch 292/500\n",
      "1137/1137 [==============================] - 0s 413us/sample - loss: 30439.7572 - val_loss: 43638.4417\n",
      "Epoch 293/500\n",
      "1137/1137 [==============================] - 0s 384us/sample - loss: 30571.8726 - val_loss: 43991.4297\n",
      "Epoch 294/500\n",
      "1137/1137 [==============================] - 0s 376us/sample - loss: 29811.5961 - val_loss: 43356.3500\n",
      "Epoch 295/500\n",
      "1137/1137 [==============================] - 0s 426us/sample - loss: 29583.0518 - val_loss: 43419.4553\n",
      "Epoch 296/500\n",
      "1137/1137 [==============================] - 1s 473us/sample - loss: 30209.0748 - val_loss: 43395.0780\n",
      "Epoch 297/500\n",
      "1137/1137 [==============================] - 0s 400us/sample - loss: 30168.8429 - val_loss: 43099.4909\n",
      "Epoch 298/500\n",
      "1137/1137 [==============================] - 0s 408us/sample - loss: 30141.5191 - val_loss: 45195.9221\n",
      "Epoch 299/500\n",
      "1137/1137 [==============================] - 0s 411us/sample - loss: 30025.5763 - val_loss: 44327.7034\n",
      "Epoch 300/500\n",
      "1137/1137 [==============================] - 0s 400us/sample - loss: 29554.7002 - val_loss: 44301.3799\n",
      "Epoch 301/500\n",
      "1137/1137 [==============================] - 0s 393us/sample - loss: 30080.3964 - val_loss: 43396.2955\n",
      "Epoch 302/500\n",
      "1137/1137 [==============================] - 1s 447us/sample - loss: 30090.2696 - val_loss: 43008.3212\n",
      "Epoch 303/500\n",
      "1137/1137 [==============================] - 0s 423us/sample - loss: 29865.2517 - val_loss: 43160.4582\n",
      "Epoch 304/500\n",
      "1137/1137 [==============================] - 0s 427us/sample - loss: 29800.3058 - val_loss: 43213.5095\n",
      "Epoch 305/500\n",
      "1137/1137 [==============================] - 0s 404us/sample - loss: 29958.9088 - val_loss: 42980.1137\n",
      "Epoch 306/500\n",
      "1137/1137 [==============================] - 1s 486us/sample - loss: 29804.7996 - val_loss: 43232.8036\n",
      "Epoch 307/500\n",
      "1137/1137 [==============================] - 0s 392us/sample - loss: 29583.1631 - val_loss: 43127.2515\n",
      "Epoch 308/500\n",
      "1137/1137 [==============================] - 0s 407us/sample - loss: 29939.7412 - val_loss: 43273.0713\n",
      "Epoch 309/500\n",
      "1137/1137 [==============================] - 1s 470us/sample - loss: 29689.8266 - val_loss: 44830.5365\n",
      "Epoch 310/500\n",
      "1137/1137 [==============================] - 1s 448us/sample - loss: 29817.4195 - val_loss: 43703.8233\n",
      "Epoch 311/500\n",
      "1137/1137 [==============================] - 0s 426us/sample - loss: 30106.1047 - val_loss: 44575.3036\n",
      "Epoch 312/500\n",
      "1137/1137 [==============================] - 1s 442us/sample - loss: 29579.1086 - val_loss: 43045.3272\n",
      "Epoch 313/500\n",
      "1137/1137 [==============================] - 0s 413us/sample - loss: 29649.8542 - val_loss: 43007.1857\n",
      "Epoch 314/500\n",
      "1137/1137 [==============================] - 0s 414us/sample - loss: 29484.3027 - val_loss: 42950.6084\n",
      "Epoch 315/500\n",
      "1137/1137 [==============================] - 0s 370us/sample - loss: 29877.8053 - val_loss: 43110.9915\n",
      "Epoch 316/500\n",
      "1137/1137 [==============================] - 0s 366us/sample - loss: 29286.7949 - val_loss: 44259.9572\n",
      "Epoch 317/500\n",
      "1137/1137 [==============================] - 1s 658us/sample - loss: 29694.9343 - val_loss: 44107.8517\n",
      "Epoch 318/500\n",
      "1137/1137 [==============================] - 1s 450us/sample - loss: 29792.2067 - val_loss: 45791.6809\n",
      "Epoch 319/500\n",
      "1137/1137 [==============================] - 1s 443us/sample - loss: 29891.9575 - val_loss: 43541.4042\n",
      "Epoch 320/500\n",
      "1137/1137 [==============================] - 0s 392us/sample - loss: 29417.6409 - val_loss: 43114.0259\n",
      "Epoch 321/500\n",
      "1137/1137 [==============================] - 0s 400us/sample - loss: 28996.5148 - val_loss: 42875.3905\n",
      "Epoch 322/500\n",
      "1137/1137 [==============================] - 0s 422us/sample - loss: 29627.5460 - val_loss: 43445.2044\n",
      "Epoch 323/500\n",
      "1137/1137 [==============================] - 0s 405us/sample - loss: 29288.0793 - val_loss: 43009.4327\n",
      "Epoch 324/500\n",
      "1137/1137 [==============================] - 0s 397us/sample - loss: 29618.3548 - val_loss: 43183.7427\n",
      "Epoch 325/500\n",
      "1137/1137 [==============================] - 0s 405us/sample - loss: 29375.6637 - val_loss: 42933.4517\n",
      "Epoch 326/500\n",
      "1137/1137 [==============================] - 0s 382us/sample - loss: 29169.1593 - val_loss: 42715.3807\n",
      "Epoch 327/500\n",
      "1137/1137 [==============================] - 0s 420us/sample - loss: 29244.8354 - val_loss: 43386.1828\n",
      "Epoch 328/500\n",
      "1137/1137 [==============================] - 0s 422us/sample - loss: 29717.1963 - val_loss: 43381.4805\n",
      "Epoch 329/500\n",
      "1137/1137 [==============================] - 1s 479us/sample - loss: 28897.2079 - val_loss: 42809.6780\n",
      "Epoch 330/500\n",
      "1137/1137 [==============================] - 1s 455us/sample - loss: 29044.8159 - val_loss: 43401.0746\n",
      "Epoch 331/500\n",
      "1137/1137 [==============================] - 1s 1ms/sample - loss: 29258.2204 - val_loss: 45545.3389\n",
      "Epoch 332/500\n",
      "1137/1137 [==============================] - 1s 456us/sample - loss: 29624.0811 - val_loss: 42911.4225\n",
      "Epoch 333/500\n",
      "1137/1137 [==============================] - 0s 412us/sample - loss: 29374.6551 - val_loss: 43333.1860\n",
      "Epoch 334/500\n",
      "1137/1137 [==============================] - 1s 542us/sample - loss: 28757.1119 - val_loss: 43005.2517\n",
      "Epoch 335/500\n",
      "1137/1137 [==============================] - 0s 417us/sample - loss: 29192.8119 - val_loss: 43063.4898\n",
      "Epoch 336/500\n",
      "1137/1137 [==============================] - 0s 420us/sample - loss: 29314.9982 - val_loss: 42810.2926\n",
      "Epoch 337/500\n",
      "1137/1137 [==============================] - 1s 589us/sample - loss: 29123.7441 - val_loss: 42970.6315\n",
      "Epoch 338/500\n",
      "1137/1137 [==============================] - 0s 379us/sample - loss: 29000.0417 - val_loss: 42814.5905\n",
      "Epoch 339/500\n",
      "1137/1137 [==============================] - 0s 369us/sample - loss: 29046.2691 - val_loss: 42807.4735\n",
      "Epoch 340/500\n",
      "1137/1137 [==============================] - 0s 396us/sample - loss: 29210.4374 - val_loss: 42798.6203\n",
      "Epoch 341/500\n",
      "1137/1137 [==============================] - 0s 383us/sample - loss: 28971.9189 - val_loss: 42810.9651\n",
      "Epoch 342/500\n",
      "1137/1137 [==============================] - 0s 434us/sample - loss: 29262.7470 - val_loss: 43387.6418\n",
      "Epoch 343/500\n",
      "1137/1137 [==============================] - 0s 420us/sample - loss: 29116.8281 - val_loss: 43435.5073\n",
      "Epoch 344/500\n",
      "1137/1137 [==============================] - 0s 363us/sample - loss: 29208.2212 - val_loss: 44121.8436\n",
      "Epoch 345/500\n",
      "1137/1137 [==============================] - 0s 376us/sample - loss: 28751.1718 - val_loss: 42693.3123\n",
      "Epoch 346/500\n",
      "1137/1137 [==============================] - 0s 348us/sample - loss: 29107.1788 - val_loss: 42505.3351\n",
      "Epoch 347/500\n",
      "1137/1137 [==============================] - 0s 396us/sample - loss: 28939.3659 - val_loss: 43677.1408\n",
      "Epoch 348/500\n",
      "1137/1137 [==============================] - 0s 413us/sample - loss: 29053.5319 - val_loss: 42568.2454\n",
      "Epoch 349/500\n",
      "1137/1137 [==============================] - 0s 377us/sample - loss: 29023.2210 - val_loss: 42792.0065\n",
      "Epoch 350/500\n",
      "1137/1137 [==============================] - 1s 443us/sample - loss: 28834.4514 - val_loss: 43675.9853\n",
      "Epoch 351/500\n",
      "1137/1137 [==============================] - 0s 351us/sample - loss: 28676.7221 - val_loss: 42497.5204\n",
      "Epoch 352/500\n",
      "1137/1137 [==============================] - 0s 379us/sample - loss: 28980.0720 - val_loss: 43587.3383\n",
      "Epoch 353/500\n",
      "1137/1137 [==============================] - 0s 418us/sample - loss: 28702.9790 - val_loss: 42732.9917\n",
      "Epoch 354/500\n",
      "1137/1137 [==============================] - 1s 590us/sample - loss: 29322.3463 - val_loss: 42628.3392\n",
      "Epoch 355/500\n",
      "1137/1137 [==============================] - 0s 423us/sample - loss: 28179.7962 - val_loss: 42384.8388\n",
      "Epoch 356/500\n",
      "1137/1137 [==============================] - 0s 387us/sample - loss: 28722.4428 - val_loss: 44374.5061\n",
      "Epoch 357/500\n",
      "1137/1137 [==============================] - 0s 396us/sample - loss: 28586.0200 - val_loss: 42378.4812\n",
      "Epoch 358/500\n",
      "1137/1137 [==============================] - 0s 385us/sample - loss: 28274.7748 - val_loss: 42568.7835\n",
      "Epoch 359/500\n",
      "1137/1137 [==============================] - 0s 366us/sample - loss: 28575.5448 - val_loss: 43060.4442\n",
      "Epoch 360/500\n",
      "1137/1137 [==============================] - 1s 463us/sample - loss: 28702.5907 - val_loss: 43108.0408\n",
      "Epoch 361/500\n",
      "1137/1137 [==============================] - 0s 412us/sample - loss: 28532.0475 - val_loss: 42286.1738\n",
      "Epoch 362/500\n",
      "1137/1137 [==============================] - 0s 344us/sample - loss: 28517.9254 - val_loss: 42542.6027\n",
      "Epoch 363/500\n",
      "1137/1137 [==============================] - 0s 409us/sample - loss: 28237.8848 - val_loss: 42608.6542\n",
      "Epoch 364/500\n",
      "1137/1137 [==============================] - 0s 428us/sample - loss: 28132.3119 - val_loss: 42377.1800\n",
      "Epoch 365/500\n",
      "1137/1137 [==============================] - 0s 399us/sample - loss: 28081.8200 - val_loss: 42415.3464\n",
      "Epoch 366/500\n",
      "1137/1137 [==============================] - 0s 376us/sample - loss: 28220.6484 - val_loss: 42519.2400\n",
      "Epoch 367/500\n",
      "1137/1137 [==============================] - 0s 376us/sample - loss: 28013.3647 - val_loss: 42680.8148\n",
      "Epoch 368/500\n",
      "1137/1137 [==============================] - 0s 391us/sample - loss: 28276.0420 - val_loss: 43003.1329\n",
      "Epoch 369/500\n",
      "1137/1137 [==============================] - 0s 363us/sample - loss: 28687.0870 - val_loss: 42392.7348\n",
      "Epoch 370/500\n",
      "1137/1137 [==============================] - 0s 392us/sample - loss: 28065.2693 - val_loss: 42956.9123\n",
      "Epoch 371/500\n",
      "1137/1137 [==============================] - 0s 365us/sample - loss: 28050.5666 - val_loss: 42251.5368\n",
      "Epoch 372/500\n",
      "1137/1137 [==============================] - 1s 502us/sample - loss: 28798.8501 - val_loss: 42363.2229\n",
      "Epoch 373/500\n",
      "1137/1137 [==============================] - 0s 391us/sample - loss: 28249.0005 - val_loss: 42389.0349\n",
      "Epoch 374/500\n",
      "1137/1137 [==============================] - 1s 511us/sample - loss: 27921.1067 - val_loss: 42432.6815\n",
      "Epoch 375/500\n",
      "1137/1137 [==============================] - 0s 437us/sample - loss: 27978.1357 - val_loss: 44244.3244\n",
      "Epoch 376/500\n",
      "1137/1137 [==============================] - 0s 427us/sample - loss: 27937.8017 - val_loss: 42353.4700\n",
      "Epoch 377/500\n",
      "1137/1137 [==============================] - 0s 415us/sample - loss: 28434.9523 - val_loss: 42179.9587\n",
      "Epoch 378/500\n",
      "1137/1137 [==============================] - 0s 430us/sample - loss: 28334.8873 - val_loss: 41895.6468\n",
      "Epoch 379/500\n",
      "1137/1137 [==============================] - 0s 422us/sample - loss: 27907.4015 - val_loss: 42260.0743\n",
      "Epoch 380/500\n",
      "1137/1137 [==============================] - 0s 417us/sample - loss: 28490.6184 - val_loss: 42271.4002\n",
      "Epoch 381/500\n",
      "1137/1137 [==============================] - 1s 534us/sample - loss: 28506.5318 - val_loss: 42174.9422\n",
      "Epoch 382/500\n",
      "1137/1137 [==============================] - 0s 400us/sample - loss: 27869.2386 - val_loss: 42111.2132\n",
      "Epoch 383/500\n",
      "1137/1137 [==============================] - 1s 450us/sample - loss: 27857.8579 - val_loss: 42039.8554\n",
      "Epoch 384/500\n",
      "1137/1137 [==============================] - 0s 420us/sample - loss: 27856.7993 - val_loss: 42745.0257\n",
      "Epoch 385/500\n",
      "1137/1137 [==============================] - 0s 381us/sample - loss: 27916.5826 - val_loss: 41885.2066\n",
      "Epoch 386/500\n",
      "1137/1137 [==============================] - 0s 421us/sample - loss: 27763.2919 - val_loss: 42040.6974\n",
      "Epoch 387/500\n",
      "1137/1137 [==============================] - 0s 394us/sample - loss: 27705.5704 - val_loss: 42046.5773\n",
      "Epoch 388/500\n",
      "1137/1137 [==============================] - 0s 410us/sample - loss: 27994.1185 - val_loss: 43105.6157\n",
      "Epoch 389/500\n",
      "1137/1137 [==============================] - 1s 639us/sample - loss: 28158.8232 - val_loss: 42384.6449\n",
      "Epoch 390/500\n",
      "1137/1137 [==============================] - 1s 495us/sample - loss: 27593.5494 - val_loss: 41778.7655\n",
      "Epoch 391/500\n",
      "1137/1137 [==============================] - 0s 414us/sample - loss: 27890.6327 - val_loss: 41939.0878\n",
      "Epoch 392/500\n",
      "1137/1137 [==============================] - 1s 451us/sample - loss: 27630.0872 - val_loss: 42286.2189\n",
      "Epoch 393/500\n",
      "1137/1137 [==============================] - 0s 380us/sample - loss: 27827.3919 - val_loss: 41918.5875\n",
      "Epoch 394/500\n",
      "1137/1137 [==============================] - 0s 417us/sample - loss: 27733.7241 - val_loss: 41883.2477\n",
      "Epoch 395/500\n",
      "1137/1137 [==============================] - 0s 410us/sample - loss: 27279.5269 - val_loss: 42042.4166\n",
      "Epoch 396/500\n",
      "1137/1137 [==============================] - 1s 479us/sample - loss: 27530.4901 - val_loss: 42247.4645\n",
      "Epoch 397/500\n",
      "1137/1137 [==============================] - 0s 437us/sample - loss: 27595.4739 - val_loss: 42491.8374\n",
      "Epoch 398/500\n",
      "1137/1137 [==============================] - 0s 409us/sample - loss: 27527.5244 - val_loss: 42147.3531\n",
      "Epoch 399/500\n",
      "1137/1137 [==============================] - 0s 423us/sample - loss: 27506.1171 - val_loss: 41797.3601\n",
      "Epoch 400/500\n",
      "1137/1137 [==============================] - 0s 411us/sample - loss: 27758.0142 - val_loss: 41880.0716\n",
      "Epoch 401/500\n",
      "1137/1137 [==============================] - 0s 377us/sample - loss: 27690.4526 - val_loss: 41547.9913\n",
      "Epoch 402/500\n",
      "1137/1137 [==============================] - 1s 459us/sample - loss: 27246.6323 - val_loss: 43102.6529\n",
      "Epoch 403/500\n",
      "1137/1137 [==============================] - 1s 491us/sample - loss: 27357.3199 - val_loss: 42417.8487\n",
      "Epoch 404/500\n",
      "1137/1137 [==============================] - 0s 418us/sample - loss: 27631.4173 - val_loss: 41863.0467\n",
      "Epoch 405/500\n",
      "1137/1137 [==============================] - 1s 442us/sample - loss: 27256.4242 - val_loss: 41523.5928\n",
      "Epoch 406/500\n",
      "1137/1137 [==============================] - 0s 404us/sample - loss: 27309.7753 - val_loss: 41423.5430\n",
      "Epoch 407/500\n",
      "1137/1137 [==============================] - 0s 372us/sample - loss: 27586.2124 - val_loss: 41551.8027\n",
      "Epoch 408/500\n",
      "1137/1137 [==============================] - 0s 414us/sample - loss: 27680.2554 - val_loss: 41731.9763\n",
      "Epoch 409/500\n",
      "1137/1137 [==============================] - 0s 415us/sample - loss: 27179.8959 - val_loss: 41734.6433\n",
      "Epoch 410/500\n",
      "1137/1137 [==============================] - 0s 407us/sample - loss: 27241.3851 - val_loss: 42273.2654\n",
      "Epoch 411/500\n",
      "1137/1137 [==============================] - 0s 417us/sample - loss: 27443.7812 - val_loss: 42228.2954\n",
      "Epoch 412/500\n",
      "1137/1137 [==============================] - 0s 370us/sample - loss: 27235.7424 - val_loss: 42066.5764\n",
      "Epoch 413/500\n",
      "1137/1137 [==============================] - 0s 418us/sample - loss: 27401.5791 - val_loss: 41870.2831\n",
      "Epoch 414/500\n",
      "1137/1137 [==============================] - 0s 390us/sample - loss: 26991.9554 - val_loss: 42115.5092\n",
      "Epoch 415/500\n",
      "1137/1137 [==============================] - 0s 430us/sample - loss: 26924.2020 - val_loss: 42118.5372\n",
      "Epoch 416/500\n",
      "1137/1137 [==============================] - 1s 458us/sample - loss: 26901.3371 - val_loss: 41452.1007\n",
      "Epoch 417/500\n",
      "1137/1137 [==============================] - 1s 479us/sample - loss: 27000.6875 - val_loss: 41546.0761\n",
      "Epoch 418/500\n",
      "1137/1137 [==============================] - 0s 427us/sample - loss: 27131.3529 - val_loss: 42290.0946\n",
      "Epoch 419/500\n",
      "1137/1137 [==============================] - 1s 458us/sample - loss: 27143.6318 - val_loss: 42102.7766\n",
      "Epoch 420/500\n",
      "1137/1137 [==============================] - 0s 407us/sample - loss: 26955.6016 - val_loss: 41269.8466\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1137/1137 [==============================] - 1s 509us/sample - loss: 27068.3278 - val_loss: 41127.8610\n",
      "Epoch 422/500\n",
      "1137/1137 [==============================] - 0s 414us/sample - loss: 26585.3687 - val_loss: 41254.1231\n",
      "Epoch 423/500\n",
      "1137/1137 [==============================] - 0s 412us/sample - loss: 26737.1342 - val_loss: 41435.0979\n",
      "Epoch 424/500\n",
      "1137/1137 [==============================] - 1s 464us/sample - loss: 27106.4386 - val_loss: 41068.9291\n",
      "Epoch 425/500\n",
      "1137/1137 [==============================] - 0s 402us/sample - loss: 26650.9388 - val_loss: 42326.0560\n",
      "Epoch 426/500\n",
      "1137/1137 [==============================] - 1s 491us/sample - loss: 26446.4152 - val_loss: 40989.3493\n",
      "Epoch 427/500\n",
      "1137/1137 [==============================] - 0s 399us/sample - loss: 26900.1723 - val_loss: 41165.5782\n",
      "Epoch 428/500\n",
      "1137/1137 [==============================] - 0s 400us/sample - loss: 27196.0761 - val_loss: 40944.4322\n",
      "Epoch 429/500\n",
      "1137/1137 [==============================] - 0s 399us/sample - loss: 26995.1074 - val_loss: 41058.8204\n",
      "Epoch 430/500\n",
      "1137/1137 [==============================] - 1s 609us/sample - loss: 26204.0334 - val_loss: 41146.9106\n",
      "Epoch 431/500\n",
      "1137/1137 [==============================] - 0s 433us/sample - loss: 26137.9722 - val_loss: 40979.1757\n",
      "Epoch 432/500\n",
      "1137/1137 [==============================] - 0s 403us/sample - loss: 27218.8421 - val_loss: 40987.2962\n",
      "Epoch 433/500\n",
      "1137/1137 [==============================] - 0s 395us/sample - loss: 26614.4310 - val_loss: 41370.8242\n",
      "Epoch 434/500\n",
      "1137/1137 [==============================] - 0s 422us/sample - loss: 26440.3623 - val_loss: 40976.5302\n",
      "Epoch 435/500\n",
      "1137/1137 [==============================] - 0s 367us/sample - loss: 26317.8478 - val_loss: 41047.6341\n",
      "Epoch 436/500\n",
      "1137/1137 [==============================] - 0s 402us/sample - loss: 26359.8541 - val_loss: 40905.2335\n",
      "Epoch 437/500\n",
      "1137/1137 [==============================] - 0s 437us/sample - loss: 26672.8439 - val_loss: 40779.4490\n",
      "Epoch 438/500\n",
      "1137/1137 [==============================] - 0s 395us/sample - loss: 26520.3335 - val_loss: 41130.9268\n",
      "Epoch 439/500\n",
      "1137/1137 [==============================] - 0s 389us/sample - loss: 27023.5058 - val_loss: 40889.6699\n",
      "Epoch 440/500\n",
      "1137/1137 [==============================] - 1s 491us/sample - loss: 26556.6823 - val_loss: 41509.0538\n",
      "Epoch 441/500\n",
      "1137/1137 [==============================] - 0s 397us/sample - loss: 26223.5480 - val_loss: 44176.3522\n",
      "Epoch 442/500\n",
      "1137/1137 [==============================] - 0s 384us/sample - loss: 26207.5207 - val_loss: 41409.0694\n",
      "Epoch 443/500\n",
      "1137/1137 [==============================] - 0s 403us/sample - loss: 26799.7473 - val_loss: 41325.0614\n",
      "Epoch 444/500\n",
      "1137/1137 [==============================] - 0s 407us/sample - loss: 26158.5624 - val_loss: 40716.9910\n",
      "Epoch 445/500\n",
      "1137/1137 [==============================] - 0s 421us/sample - loss: 26428.2196 - val_loss: 41635.3522\n",
      "Epoch 446/500\n",
      "1137/1137 [==============================] - 0s 424us/sample - loss: 26453.1511 - val_loss: 40795.5096\n",
      "Epoch 447/500\n",
      "1137/1137 [==============================] - 0s 410us/sample - loss: 26061.8647 - val_loss: 40651.7963\n",
      "Epoch 448/500\n",
      "1137/1137 [==============================] - 0s 413us/sample - loss: 26407.7254 - val_loss: 40695.5382\n",
      "Epoch 449/500\n",
      "1137/1137 [==============================] - 0s 363us/sample - loss: 26102.0689 - val_loss: 41393.6032\n",
      "Epoch 450/500\n",
      "1137/1137 [==============================] - 0s 419us/sample - loss: 26078.8532 - val_loss: 40807.1143\n",
      "Epoch 451/500\n",
      "1137/1137 [==============================] - 0s 425us/sample - loss: 26173.1323 - val_loss: 40566.1126\n",
      "Epoch 452/500\n",
      "1137/1137 [==============================] - 0s 412us/sample - loss: 26305.5070 - val_loss: 41644.4063\n",
      "Epoch 453/500\n",
      "1137/1137 [==============================] - 0s 381us/sample - loss: 26232.8328 - val_loss: 41175.8633\n",
      "Epoch 454/500\n",
      "1137/1137 [==============================] - 0s 388us/sample - loss: 26000.1368 - val_loss: 40512.7484\n",
      "Epoch 455/500\n",
      "1137/1137 [==============================] - 0s 364us/sample - loss: 26182.6687 - val_loss: 40600.9281\n",
      "Epoch 456/500\n",
      "1137/1137 [==============================] - 1s 452us/sample - loss: 25775.9086 - val_loss: 40111.5346\n",
      "Epoch 457/500\n",
      "1137/1137 [==============================] - 0s 377us/sample - loss: 26146.9746 - val_loss: 40456.3738\n",
      "Epoch 458/500\n",
      "1137/1137 [==============================] - 0s 405us/sample - loss: 26182.0228 - val_loss: 40515.1817\n",
      "Epoch 459/500\n",
      "1137/1137 [==============================] - 1s 472us/sample - loss: 26024.3472 - val_loss: 40633.3942\n",
      "Epoch 460/500\n",
      "1137/1137 [==============================] - 1s 453us/sample - loss: 26217.6784 - val_loss: 40490.5740\n",
      "Epoch 461/500\n",
      "1137/1137 [==============================] - 0s 363us/sample - loss: 26035.7455 - val_loss: 41324.2525\n",
      "Epoch 462/500\n",
      "1137/1137 [==============================] - 0s 414us/sample - loss: 25454.8080 - val_loss: 40876.0135\n",
      "Epoch 463/500\n",
      "1137/1137 [==============================] - 0s 388us/sample - loss: 25545.4787 - val_loss: 40559.3695\n",
      "Epoch 464/500\n",
      "1137/1137 [==============================] - 0s 437us/sample - loss: 25873.1311 - val_loss: 40202.9887\n",
      "Epoch 465/500\n",
      "1137/1137 [==============================] - 0s 400us/sample - loss: 25948.4627 - val_loss: 40169.9416\n",
      "Epoch 466/500\n",
      "1137/1137 [==============================] - 0s 383us/sample - loss: 25429.8123 - val_loss: 41119.6797\n",
      "Epoch 467/500\n",
      "1137/1137 [==============================] - 0s 432us/sample - loss: 25514.0325 - val_loss: 41011.7438\n",
      "Epoch 468/500\n",
      "1137/1137 [==============================] - 0s 381us/sample - loss: 25532.0033 - val_loss: 41659.6997\n",
      "Epoch 469/500\n",
      "1137/1137 [==============================] - 0s 411us/sample - loss: 25597.2797 - val_loss: 41865.5560\n",
      "Epoch 470/500\n",
      "1137/1137 [==============================] - 0s 362us/sample - loss: 25702.7229 - val_loss: 41747.1926\n",
      "Epoch 471/500\n",
      "1137/1137 [==============================] - 0s 403us/sample - loss: 25740.1937 - val_loss: 40094.1409\n",
      "Epoch 472/500\n",
      "1137/1137 [==============================] - 0s 407us/sample - loss: 25827.1010 - val_loss: 41241.1943\n",
      "Epoch 473/500\n",
      "1137/1137 [==============================] - 1s 606us/sample - loss: 25517.3378 - val_loss: 40303.3909\n",
      "Epoch 474/500\n",
      "1137/1137 [==============================] - 0s 415us/sample - loss: 25298.9801 - val_loss: 40916.5305\n",
      "Epoch 475/500\n",
      "1137/1137 [==============================] - 0s 428us/sample - loss: 25591.2490 - val_loss: 41072.3311\n",
      "Epoch 476/500\n",
      "1137/1137 [==============================] - 0s 377us/sample - loss: 25498.4930 - val_loss: 39891.0074\n",
      "Epoch 477/500\n",
      "1137/1137 [==============================] - 0s 401us/sample - loss: 25405.8442 - val_loss: 40661.5988\n",
      "Epoch 478/500\n",
      "1137/1137 [==============================] - 0s 417us/sample - loss: 25564.9714 - val_loss: 40207.7447\n",
      "Epoch 479/500\n",
      "1137/1137 [==============================] - 1s 454us/sample - loss: 25176.6839 - val_loss: 42097.7215\n",
      "Epoch 480/500\n",
      "1137/1137 [==============================] - 0s 403us/sample - loss: 25422.3147 - val_loss: 40333.1416\n",
      "Epoch 481/500\n",
      "1137/1137 [==============================] - 0s 398us/sample - loss: 25399.5525 - val_loss: 40173.1800\n",
      "Epoch 482/500\n",
      "1137/1137 [==============================] - 1s 543us/sample - loss: 24702.5756 - val_loss: 41184.4609\n",
      "Epoch 483/500\n",
      "1137/1137 [==============================] - 1s 542us/sample - loss: 25245.1465 - val_loss: 40265.5435\n",
      "Epoch 484/500\n",
      "1137/1137 [==============================] - 1s 544us/sample - loss: 24973.7708 - val_loss: 40378.8384\n",
      "Epoch 485/500\n",
      "1137/1137 [==============================] - 1s 532us/sample - loss: 24906.4758 - val_loss: 39966.9125\n",
      "Epoch 486/500\n",
      "1137/1137 [==============================] - 1s 481us/sample - loss: 25315.9253 - val_loss: 40426.0195\n",
      "Epoch 487/500\n",
      "1137/1137 [==============================] - 1s 552us/sample - loss: 25188.4990 - val_loss: 40422.6300\n",
      "Epoch 488/500\n",
      "1137/1137 [==============================] - 1s 559us/sample - loss: 24985.3613 - val_loss: 39626.6554\n",
      "Epoch 489/500\n",
      "1137/1137 [==============================] - 1s 539us/sample - loss: 24808.6425 - val_loss: 40273.7318\n",
      "Epoch 490/500\n",
      "1137/1137 [==============================] - 1s 472us/sample - loss: 25304.8955 - val_loss: 39737.3556\n",
      "Epoch 491/500\n",
      "1137/1137 [==============================] - 1s 469us/sample - loss: 25110.1702 - val_loss: 40305.9846\n",
      "Epoch 492/500\n",
      "1137/1137 [==============================] - 0s 408us/sample - loss: 24712.8367 - val_loss: 39990.3596\n",
      "Epoch 493/500\n",
      "1137/1137 [==============================] - 0s 429us/sample - loss: 24883.3530 - val_loss: 41928.8588\n",
      "Epoch 494/500\n",
      "1137/1137 [==============================] - 1s 477us/sample - loss: 24800.2032 - val_loss: 40243.9490\n",
      "Epoch 495/500\n",
      "1137/1137 [==============================] - 0s 429us/sample - loss: 25261.7467 - val_loss: 39966.5642\n",
      "Epoch 496/500\n",
      "1137/1137 [==============================] - 0s 398us/sample - loss: 24593.2399 - val_loss: 39405.5829\n",
      "Epoch 497/500\n",
      "1137/1137 [==============================] - 0s 396us/sample - loss: 24536.2933 - val_loss: 39445.5573\n",
      "Epoch 498/500\n",
      "1137/1137 [==============================] - 0s 379us/sample - loss: 24541.6361 - val_loss: 39608.0809\n",
      "Epoch 499/500\n",
      "1137/1137 [==============================] - 0s 381us/sample - loss: 24689.5590 - val_loss: 40578.0324\n",
      "Epoch 500/500\n",
      "1137/1137 [==============================] - 0s 408us/sample - loss: 24891.6475 - val_loss: 39777.0453\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='elu',input_dim = 174), \n",
    "    tf.keras.layers.Dense(25,  activation='elu'),\n",
    "    tf.keras.layers.Dense(50, activation='elu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# learning_rate = 0.1\n",
    "# decay_rate = learning_rate / 500\n",
    "# def exp_decay(epoch):\n",
    "#     lrate = learning_rate * np.exp(-decay_rate*epoch)\n",
    "#     return lrate\n",
    "# lr_schedule = tf.keras.callbacks.LearningRateScheduler(exp_decay)\n",
    "\n",
    "# lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "#     lambda epoch: 1e-8 * 10**(epoch / 10))\n",
    "\n",
    "model.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "history = model.fit(X_train.values, y_train.values, validation_split=0.20, batch_size = 10, epochs=500,verbose=1)#,callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#optimizer = 'Adamax'\n",
    "import matplotlib.pyplot as plt\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=model.predict(df_test.drop(['SalePrice'],axis=1).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119980.18],\n",
       "       [157477.95],\n",
       "       [192092.48],\n",
       "       ...,\n",
       "       [168594.73],\n",
       "       [114930.38],\n",
       "       [206490.64]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(ann_pred)\n",
    "sub_df = pd.read_csv('sample_submission.csv')\n",
    "dataset = pd.concat([sub_df['Id'], pred], axis= 1)\n",
    "dataset.columns= ['Id', 'SalePrice']\n",
    "dataset.to_csv('my_submission_NN.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
